{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75e05bdb",
   "metadata": {},
   "source": [
    "# Hierarchical Fusion for Multimodal Sarcasm Detection\n",
    "**Author:** Anoop Singh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf348159",
   "metadata": {},
   "source": [
    "## Motivation\n",
    "Sarcasm is a linguistic device that conveys meaning by saying the opposite of what is actually intended. It's a frequent phenomenon in social media and plays a critical role in understanding sentiment, intent, and context in user-generated content.\n",
    "\n",
    "While text alone has been the traditional focus of sarcasm detection, we observe a growing use of multimodal contentâ€”especially in platforms like Twitter where users frequently combine text with images. Detecting sarcasm from such content based solely on the text misses important visual and contextual cues. \n",
    "\n",
    "For example, a tweet like:\n",
    "\n",
    "    \"Yum, hospital cafeteria food!\"\n",
    "\n",
    "\n",
    "![Model Architecture](eg.png)\n",
    "\n",
    "\n",
    "â€¦ is obviously sarcasticâ€”but only when you see the image.\n",
    "\n",
    "This motivated us to explore a more robust sarcasm detection approach using Hierarchical Fusion of three modalities:\n",
    "\n",
    "    Text (tweet content),\n",
    "\n",
    "    Image (attached visual),\n",
    "\n",
    "    Image Attributes (e.g., objects, colors, scenes inferred from the image)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6e205e",
   "metadata": {},
   "source": [
    "\n",
    "## Background: From Text to Multimodal Sarcasm Detection\n",
    "\n",
    "### Historical Perspective on Sarcasm Detection:\n",
    "\n",
    "* **Early Work**: Focused on handcrafted features like n-grams, punctuation, or sentiment shift (Riloff et al., 2013).\n",
    "* **Deep Learning Phase**: Models like CNNs, LSTMs, and attention mechanisms emerged (Ghosh & Veale, 2016; Baziotis et al., 2018), yielding better results on text alone.\n",
    "* **Multimodal Beginnings**: Schifanella et al. (2016) were among the first to explore sarcasm in multimodal tweets using simple feature concatenation of image and text.\n",
    "\n",
    "### Whatâ€™s New in This Work?\n",
    "\n",
    "Cai et al. (2019) proposed a **Hierarchical Fusion Model**, which:\n",
    "\n",
    "* Uses *three modalities*: text, image, and image attributes.\n",
    "* Applies *fusion in stages*: early (for context initialization), representation (for attention-guided encoding), and modality fusion (for final integration).\n",
    "* Outperforms unimodal and naÃ¯ve fusion approaches significantly.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd38c4a1",
   "metadata": {},
   "source": [
    "## Learnings from This Work\n",
    "\n",
    "Hereâ€™s what we gained from implementing and exploring this model:\n",
    "\n",
    "* **Attributes matter**: Object and color tags extracted from images help \"translate\" visual information into something the model can relate to the text.\n",
    "* **Early fusion boosts performance**: Using attribute embeddings to initialize the text encoder (Bi-LSTM) improves semantic alignment.\n",
    "* **Hierarchical fusion is effective**: Combining features in structured stages yields better results than simply concatenating them.\n",
    "* **Attention mechanisms** enhance interpretability, showing where the model is focusingâ€”be it on certain words, image regions, or specific attributes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c56966",
   "metadata": {},
   "source": [
    "\n",
    "## Code Snippet â€“ Attention Over Attributes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68189c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplified example: attention weights for attribute guidance\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Dummy attribute embeddings\n",
    "attributes = torch.randn(5, 200)  # 5 attributes, 200-dim each\n",
    "W1 = torch.randn(128, 200)\n",
    "W2 = torch.randn(1, 128)\n",
    "b1 = torch.randn(128)\n",
    "b2 = torch.randn(1)\n",
    "\n",
    "# Attention score computation\n",
    "alpha = W2 @ torch.tanh(W1 @ attributes.T + b1[:, None]) + b2\n",
    "attention_weights = F.softmax(alpha, dim=1)\n",
    "print('Attention Weights:', attention_weights)\n",
    "\n",
    "# This approximates how the model gives importance to different attributes before fusing them with other modalities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a40cb8",
   "metadata": {},
   "source": [
    "\n",
    "## ðŸ“Š Results\n",
    "\n",
    "To evaluate the modelâ€™s performance on multimodal sarcasm detection, we used metrics such as **accuracy**, **precision**, **recall**, and **F1-score**. Here we also visualize:\n",
    "\n",
    "* The **confusion matrix** to show classification distribution.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6eec86b",
   "metadata": {},
   "source": [
    "![image.png](image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7f0fca",
   "metadata": {},
   "outputs": [],
   "source": [
    ">>>Example 1<<<\n",
    "Text:  as we all know , calligraphy is one of the artsy-trendy ! grab a personalized notebook and get yours for only php 50\n",
    "Labels:  ['sign', 'painted', 'sand', 'says', 'bed']\n",
    "Truth: not sarcasm\n",
    "Preduct: not sarcasm\n",
    ">>>Example 1<<<\n",
    "Text:  i will not remain silent . israel and the temple mount belong to the jews . <user> <user> <user>\n",
    "Labels:  ['building', 'large', 'parked', 'people', 'landing']\n",
    "Truth: not sarcasm\n",
    "Preduct: not sarcasm\n",
    ">>>Example 1<<<\n",
    "Text:  today 's winner of the kia : bandwagon fan of the day award , <user> ! # warriorsbandwagon emoji_1031\n",
    "Labels:  ['happy', 'bun', 'phone', 'bathroom', 'cellphone']\n",
    "Truth: not sarcasm\n",
    "Preduct: not sarcasm\n",
    ">>>Example 1<<<\n",
    "Text:  larries out here living the treat people with kindness life . # eyeroll \n",
    "Labels:  ['picture', 'birds', 'perched', 'screen', 'showing']\n",
    "Truth: sarcasm\n",
    "Preduct: sarcasm\n",
    ">>>Example 1<<<\n",
    "Text:  the saying of \" i 'm going to hell for this or laughing at this \" is quite often . # myhumorisdark  # andbeing # savage is part of me now\n",
    "Labels:  ['painting', 'old', 'picture', 'photo', 'woman']\n",
    "Truth: sarcasm\n",
    "Preduct: sarcasm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f803ca7",
   "metadata": {},
   "source": [
    "## Reflections\n",
    "\n",
    "### What surprised me?\n",
    "\n",
    "* How much performance improved **just by using object-level image information**.\n",
    "* Some sarcastic tweets are virtually impossible to interpret correctly without imagesâ€”especially when the text is neutral or positive in tone.\n",
    "\n",
    "### What can be improved?\n",
    "\n",
    "* The model doesnâ€™t yet use **transformers** or **vision-language pretraining (e.g., CLIP, BLIP)**â€”which could dramatically enhance both alignment and generalization.\n",
    "* **Commonsense reasoning** is still missing; sarcasm often relies on unstated knowledge.\n",
    "* Training on larger or multilingual datasets would help validate the method across different cultures and languages.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7edbe7",
   "metadata": {},
   "source": [
    "\n",
    "## References\n",
    "\n",
    "* Cai et al., 2019. [Multi-Modal Sarcasm Detection in Twitter with Hierarchical Fusion Model](https://aclanthology.org/P19-1239.pdf)\n",
    "* Ghosh & Veale, 2016. Fracking Sarcasm Using Neural Networks.\n",
    "* Schifanella et al., 2016. Detecting Sarcasm in Multimodal Social Platforms.\n",
    "* Pennington et al., 2014. GloVe: Global Vectors for Word Representation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68283bd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
